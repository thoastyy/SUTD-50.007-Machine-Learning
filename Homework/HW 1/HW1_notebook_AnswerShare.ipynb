{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Perceptron \n",
    "This exercise requires the student to understand the basics of linear classification using perceptron update rule. To start any machine learning task, it requires data exploration and data cleaning. We will be using a real-life dataset from NBA which includes details about rookie basketball players such as games played, points per game, rebounds, assists and blocks to predict if the player will be in NBA after 5 years. To get more details about the dataset, please explore the link provided below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://data.world/exercises/logistic-regression-exercise-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data\n",
    "To start of, we will be making use of pandas library to read and do brief data cleaning. We will be using the nba_data_train.csv to train our model and this model will be tested for its performance using the nba_data_test.csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon Ingram</td>\n",
       "      <td>36</td>\n",
       "      <td>27.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Harrison</td>\n",
       "      <td>35</td>\n",
       "      <td>26.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JaKarr Sampson</td>\n",
       "      <td>74</td>\n",
       "      <td>15.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik Sealy</td>\n",
       "      <td>58</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Geiger</td>\n",
       "      <td>48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>67.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Jamaal Tinsley</td>\n",
       "      <td>80</td>\n",
       "      <td>30.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>70.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Sonny Parker</td>\n",
       "      <td>77</td>\n",
       "      <td>29.4</td>\n",
       "      <td>9.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.3</td>\n",
       "      <td>41.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>67.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Trenton Hassell</td>\n",
       "      <td>78</td>\n",
       "      <td>28.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>8.1</td>\n",
       "      <td>42.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>36.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>76.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Justin Anderson</td>\n",
       "      <td>55</td>\n",
       "      <td>11.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>40.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Eddie Griffin</td>\n",
       "      <td>73</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>9.1</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>74.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name  GP   MIN  PTS  FGM  FGA   FG%  3P Made  3PA   3P%  ...  \\\n",
       "0     Brandon Ingram  36  27.4  7.4  2.6  7.6  34.7      0.5  2.1  25.0  ...   \n",
       "1    Andrew Harrison  35  26.9  7.2  2.0  6.7  29.6      0.7  2.8  23.5  ...   \n",
       "2     JaKarr Sampson  74  15.3  5.2  2.0  4.7  42.2      0.4  1.7  24.4  ...   \n",
       "3        Malik Sealy  58  11.6  5.7  2.3  5.5  42.6      0.1  0.5  22.6  ...   \n",
       "4        Matt Geiger  48  11.5  4.5  1.6  3.0  52.4      0.0  0.1   0.0  ...   \n",
       "..               ...  ..   ...  ...  ...  ...   ...      ...  ...   ...  ...   \n",
       "995   Jamaal Tinsley  80  30.5  9.4  3.6  9.5  38.0      0.5  2.2  24.0  ...   \n",
       "996     Sonny Parker  77  29.4  9.2  3.5  8.3  41.9      0.8  2.5  32.3  ...   \n",
       "997  Trenton Hassell  78  28.7  8.7  3.4  8.1  42.5      0.8  2.1  36.4  ...   \n",
       "998  Justin Anderson  55  11.8  3.8  1.3  3.2  40.6      0.4  1.5  26.5  ...   \n",
       "999    Eddie Griffin  73  26.0  8.8  3.3  9.1  36.6      1.2  3.7  33.0  ...   \n",
       "\n",
       "     FTA   FT%  OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0    2.3  69.9   0.7   3.4  4.1  1.9  0.4  0.4  1.3           -1  \n",
       "1    3.4  76.5   0.5   2.0  2.4  3.7  1.1  0.5  1.6           -1  \n",
       "2    1.3  67.0   0.5   1.7  2.2  1.0  0.5  0.3  1.0           -1  \n",
       "3    1.3  68.9   1.0   0.9  1.9  0.8  0.6  0.1  1.0            1  \n",
       "4    1.9  67.4   1.0   1.5  2.5  0.3  0.3  0.4  0.8            1  \n",
       "..   ...   ...   ...   ...  ...  ...  ...  ...  ...          ...  \n",
       "995  2.3  70.4   1.0   2.8  3.7  8.1  1.7  0.5  3.4            1  \n",
       "996  2.1  67.5   0.4   2.1  2.6  4.3  1.2  0.1  2.0            1  \n",
       "997  1.5  76.3   0.8   2.4  3.3  2.2  0.7  0.6  1.3            1  \n",
       "998  1.0  80.0   0.3   2.1  2.4  0.5  0.3  0.5  0.4           -1  \n",
       "999  1.2  74.4   1.6   4.1  5.7  0.7  0.2  1.8  0.6            1  \n",
       "\n",
       "[1000 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading \"nba_data_train.csv\" into variable \"df\" [2 points]\n",
    "df = pd.read_csv(\"nba_data_train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above code block, we can see the number of rows and columns in the given dataset. To see the values for each column for our first row, please run the code block given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name           Brandon Ingram\n",
       "GP                         36\n",
       "MIN                      27.4\n",
       "PTS                       7.4\n",
       "FGM                       2.6\n",
       "FGA                       7.6\n",
       "FG%                      34.7\n",
       "3P Made                   0.5\n",
       "3PA                       2.1\n",
       "3P%                      25.0\n",
       "FTM                       1.6\n",
       "FTA                       2.3\n",
       "FT%                      69.9\n",
       "OREB                      0.7\n",
       "DREB                      3.4\n",
       "REB                       4.1\n",
       "AST                       1.9\n",
       "STL                       0.4\n",
       "BLK                       0.4\n",
       "TOV                       1.3\n",
       "TARGET_5Yrs                -1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe, almost all the features are numbers except the name of the player. However, we are not sure if our dataset has any missing values. To tackle this problem, we could either remove the null valued row or column or replace the value with either median value or a user defined value. For our dataset, make use of an in-built function in pandas to remove all the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon Ingram</td>\n",
       "      <td>36</td>\n",
       "      <td>27.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrew Harrison</td>\n",
       "      <td>35</td>\n",
       "      <td>26.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JaKarr Sampson</td>\n",
       "      <td>74</td>\n",
       "      <td>15.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Malik Sealy</td>\n",
       "      <td>58</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Geiger</td>\n",
       "      <td>48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>67.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Jamaal Tinsley</td>\n",
       "      <td>80</td>\n",
       "      <td>30.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>70.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Sonny Parker</td>\n",
       "      <td>77</td>\n",
       "      <td>29.4</td>\n",
       "      <td>9.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.3</td>\n",
       "      <td>41.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>67.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Trenton Hassell</td>\n",
       "      <td>78</td>\n",
       "      <td>28.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>8.1</td>\n",
       "      <td>42.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>36.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>76.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Justin Anderson</td>\n",
       "      <td>55</td>\n",
       "      <td>11.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>40.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Eddie Griffin</td>\n",
       "      <td>73</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>9.1</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>74.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name  GP   MIN  PTS  FGM  FGA   FG%  3P Made  3PA   3P%  ...  \\\n",
       "0     Brandon Ingram  36  27.4  7.4  2.6  7.6  34.7      0.5  2.1  25.0  ...   \n",
       "1    Andrew Harrison  35  26.9  7.2  2.0  6.7  29.6      0.7  2.8  23.5  ...   \n",
       "2     JaKarr Sampson  74  15.3  5.2  2.0  4.7  42.2      0.4  1.7  24.4  ...   \n",
       "3        Malik Sealy  58  11.6  5.7  2.3  5.5  42.6      0.1  0.5  22.6  ...   \n",
       "4        Matt Geiger  48  11.5  4.5  1.6  3.0  52.4      0.0  0.1   0.0  ...   \n",
       "..               ...  ..   ...  ...  ...  ...   ...      ...  ...   ...  ...   \n",
       "995   Jamaal Tinsley  80  30.5  9.4  3.6  9.5  38.0      0.5  2.2  24.0  ...   \n",
       "996     Sonny Parker  77  29.4  9.2  3.5  8.3  41.9      0.8  2.5  32.3  ...   \n",
       "997  Trenton Hassell  78  28.7  8.7  3.4  8.1  42.5      0.8  2.1  36.4  ...   \n",
       "998  Justin Anderson  55  11.8  3.8  1.3  3.2  40.6      0.4  1.5  26.5  ...   \n",
       "999    Eddie Griffin  73  26.0  8.8  3.3  9.1  36.6      1.2  3.7  33.0  ...   \n",
       "\n",
       "     FTA   FT%  OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0    2.3  69.9   0.7   3.4  4.1  1.9  0.4  0.4  1.3           -1  \n",
       "1    3.4  76.5   0.5   2.0  2.4  3.7  1.1  0.5  1.6           -1  \n",
       "2    1.3  67.0   0.5   1.7  2.2  1.0  0.5  0.3  1.0           -1  \n",
       "3    1.3  68.9   1.0   0.9  1.9  0.8  0.6  0.1  1.0            1  \n",
       "4    1.9  67.4   1.0   1.5  2.5  0.3  0.3  0.4  0.8            1  \n",
       "..   ...   ...   ...   ...  ...  ...  ...  ...  ...          ...  \n",
       "995  2.3  70.4   1.0   2.8  3.7  8.1  1.7  0.5  3.4            1  \n",
       "996  2.1  67.5   0.4   2.1  2.6  4.3  1.2  0.1  2.0            1  \n",
       "997  1.5  76.3   0.8   2.4  3.3  2.2  0.7  0.6  1.3            1  \n",
       "998  1.0  80.0   0.3   2.1  2.4  0.5  0.3  0.5  0.4           -1  \n",
       "999  1.2  74.4   1.6   4.1  5.7  0.7  0.2  1.8  0.6            1  \n",
       "\n",
       "[989 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove all the null values using a built-in function [2 points]\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing all the null values from the dataset, we can separate the columns into features which are used as an input for our model and target which is the predicted value by our model. (hint: remember to remove \"Name\" column for your feature vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of target :  (989,)\n",
      "Shape of features :  (989, 19)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[36. , 27.4,  7.4, ...,  0.4,  0.4,  1.3],\n",
       "       [35. , 26.9,  7.2, ...,  1.1,  0.5,  1.6],\n",
       "       [74. , 15.3,  5.2, ...,  0.5,  0.3,  1. ],\n",
       "       ...,\n",
       "       [78. , 28.7,  8.7, ...,  0.7,  0.6,  1.3],\n",
       "       [55. , 11.8,  3.8, ...,  0.3,  0.5,  0.4],\n",
       "       [73. , 26. ,  8.8, ...,  0.2,  1.8,  0.6]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = df['TARGET_5Yrs'].to_numpy()\n",
    "train_features = df.drop(['Name','TARGET_5Yrs'], axis = 1).to_numpy()\n",
    "print(\"Shape of target : \", train_target.shape)\n",
    "print(\"Shape of features : \", train_features.shape)\n",
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo: Fill up the functions given below to implement a linear classifier with perceptron update rule. It is encouraged to make use of numpy library as it is computationally efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Through this function, you need to define initial values (which are all 0) of our theta vector and offset.\n",
    "#\"n\" is the number of dimensions for feature vectors.\n",
    "#This question worth [3 points]\n",
    "def init_params_with_zeroes(n): \n",
    "    ### TODO ##\n",
    "    theta = np.array([0.0]*n)\n",
    "    offset = 0.0\n",
    "    return theta, offset\n",
    "    ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]),\n",
       " 0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_params_with_zeroes(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Through this function, you need to define initial values (which are all 1) of our theta vector and offset.\n",
    "#\"n\" is the number of dimensions for feature vectors.\n",
    "#This question worth [3 points]\n",
    "def init_params_with_ones(n):\n",
    "    ### TODO ##\n",
    "    theta = np.array([1.0]*n)\n",
    "    offset = 1.0\n",
    "    return theta, offset\n",
    "    ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.]),\n",
       " 1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_params_with_ones(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Through this function, you need to define initial values (which are all random values) of our theta vector and offset.\n",
    "#\"n\" is the number of dimensions for feature vectors.\n",
    "#This question worth [3 points]\n",
    "def init_params_with_random(n): \n",
    "    ### TODO ##\n",
    "    theta = np.array([random.Random(1).random() for i in range(n)])\n",
    "    offset = random.Random(1).random()\n",
    "    return theta, offset\n",
    "    ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.13436424, 0.13436424, 0.13436424, 0.13436424, 0.13436424,\n",
       "        0.13436424, 0.13436424, 0.13436424, 0.13436424, 0.13436424,\n",
       "        0.13436424, 0.13436424, 0.13436424, 0.13436424, 0.13436424,\n",
       "        0.13436424, 0.13436424, 0.13436424, 0.13436424]),\n",
       " 0.13436424411240122)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_params_with_random(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Through this function, you need to write from scratch of a perceptron training algorithms without offset.\n",
    "#for the input: \"theta\" is the initial theta vector, \"xs\" is our feature vectors from the training dataset.\n",
    "#\"ys\" is the output vector (the vector of \"labels\"), \"epochs\" is the number of times your \"perceptron algorithm\" run through the whole training dataset.\n",
    "#This question worth [6 points]\n",
    "\n",
    "def train_perceptron_without_offset(theta, xs, ys, epochs): \n",
    "    ### TODO ##\n",
    "    while epochs>0:\n",
    "        for i,j in zip(xs, ys):\n",
    "            if j*(np.dot(i, theta))<=0:\n",
    "                theta += i*j\n",
    "        epochs-=1\n",
    "            \n",
    "    return theta\n",
    "    ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Through this function, you need to write from scratch of a perceptron training algorithms with offset.\n",
    "#for the input: \"theta\" is the initial theta vector, \"offset\" is the initial offset velue, \"xs\" is our feature vectors from the training dataset.\n",
    "#\"ys\" is the output vector (the vector of \"labels\"), \"epochs\" is the number of times your \"perceptron algorithm\" run through the whole training dataset.\n",
    "#This question worth [6 points]\n",
    "\n",
    "def train_perceptron_with_offset(theta, offset, xs, ys, epochs):\n",
    "    ### TODO ##\n",
    "    while epochs>0:\n",
    "        for i,j in zip(xs, ys):\n",
    "            if j*(np.dot(i, theta) + offset)<=0:\n",
    "                theta += i*j\n",
    "                offset += j\n",
    "        epochs-=1\n",
    "            \n",
    "    return theta, offset\n",
    "    ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_perceptron(theta, offset, xs, ys):\n",
    "    test_count = len(xs)\n",
    "    # The below line is a vectorized way of checking if y(θx+θo) > 0 for all x and y\n",
    "    results = ys * (xs.dot(theta) + offset) > 0.0  # returns True/False array\n",
    "    correct = results.sum()\n",
    "    return correct / test_count, correct, test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nba_data_test.csv\")\n",
    "test_target = df['TARGET_5Yrs'].to_numpy()\n",
    "test_features = df.drop(['Name','TARGET_5Yrs'], axis = 1).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) With zeroes as initial parameters over 1 epoch and no offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 5 epochs:\n",
      "Theta [172.   76.7 145.2  53.6  83.1 -40.4   0.5  -9.6  34.5  36.2  40.  -44.\n",
      "  25.7  30.4  57.1   7.9   4.    3.1  16.3]\n",
      "Test accuracy 67.3529411764706% (229 of 340)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta, offset = init_params_with_zeroes(len(train_features[0]))\n",
    "theta = train_perceptron_without_offset(theta, train_features, train_target,1)\n",
    "acc, correct, test_count = test_perceptron(theta, 0, test_features, test_target)\n",
    "print(f'Results after 5 epochs:\\n'\n",
    "      f'Theta {theta}\\n'\n",
    "      f'Test accuracy {acc*100}% ({correct} of {test_count})\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) With zeroes as initial parameters over 1 epoch with offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 5 epochs:\n",
      "Theta [172.   76.7 145.2  53.6  83.1 -40.4   0.5  -9.6  34.5  36.2  40.  -44.\n",
      "  25.7  30.4  57.1   7.9   4.    3.1  16.3]\n",
      "Offset -8.0\n",
      "Test accuracy 67.3529411764706% (229 of 340)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta, offset = init_params_with_zeroes(len(train_features[0]))\n",
    "theta, offset = train_perceptron_with_offset(theta, offset, train_features, train_target,1)\n",
    "acc, correct, test_count = test_perceptron(theta, offset, test_features, test_target)\n",
    "print(f'Results after 5 epochs:\\n'\n",
    "      f'Theta {theta}\\nOffset {offset}\\n'\n",
    "      f'Test accuracy {acc*100}% ({correct} of {test_count})\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) With zeroes as initial parameters over 5 epochs with offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 5 epochs:\n",
      "Theta [ 250.  -118.2  372.7  124.6  125.6  -56.9   -9.9  -73.6   -9.5  127.9\n",
      "  132.4 -100.4   80.4    7.2   92.   -15.7   13.7   -3.1   27.4]\n",
      "Offset -36.0\n",
      "Test accuracy 68.82352941176471% (234 of 340)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta, offset = init_params_with_zeroes(len(train_features[0]))\n",
    "theta, offset = train_perceptron_with_offset(theta, offset, train_features, train_target,5)\n",
    "acc, correct, test_count = test_perceptron(theta, offset, test_features, test_target)\n",
    "print(f'Results after 5 epochs:\\n'\n",
    "      f'Theta {theta}\\nOffset {offset}\\n'\n",
    "      f'Test accuracy {acc*100}% ({correct} of {test_count})\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) With ones as initial parameters over 5 epochs with offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 5 epochs:\n",
      "Theta [ 200.  -136.4  375.9  127.6  124.3  -32.9  -16.7  -99.2   43.3  136.\n",
      "  140.5  -47.4   90.5   19.5  112.4  -10.7   10.3   -1.2   26.8]\n",
      "Offset -35.0\n",
      "Test accuracy 67.3529411764706% (229 of 340)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta, offset = init_params_with_ones(len(train_features[0]))\n",
    "theta, offset = train_perceptron_with_offset(theta, offset, train_features, train_target, 5)\n",
    "acc, correct, test_count = test_perceptron(theta, offset, test_features, test_target)\n",
    "print(f'Results after 5 epochs:\\n'\n",
    "      f'Theta {theta}\\nOffset {offset}\\n'\n",
    "      f'Test accuracy {acc*100}% ({correct} of {test_count})\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) With random as initial parameters over 5 epochs with offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 5 epochs:\n",
      "Theta [ 175.13436424 -127.96563576  396.43436424  135.03436424  138.83436424\n",
      "  -49.16563576  -11.06563576  -79.46563576   64.53436424  133.23436424\n",
      "  134.53436424  -41.46563576   72.53436424   -1.16563576   77.33436424\n",
      "    6.73436424   15.63436424   -4.96563576   34.73436424]\n",
      "Offset -36.865635755887595\n",
      "Test accuracy 67.64705882352942% (230 of 340)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta, offset = init_params_with_random(len(train_features[0]))\n",
    "theta, offset = train_perceptron_with_offset(theta, offset, train_features, train_target, 5)\n",
    "acc, correct, test_count = test_perceptron(theta, offset, test_features, test_target)\n",
    "print(f'Results after 5 epochs:\\n'\n",
    "      f'Theta {theta}\\nOffset {offset}\\n'\n",
    "      f'Test accuracy {acc*100}% ({correct} of {test_count})\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) With ones as initial parameters over 10 epochs with offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 10 epochs:\n",
      "Theta [ 258.  -277.7  558.2  182.6   93.4  -69.7  -27.3 -182.3   36.1  216.8\n",
      "  199.8  -57.6  142.2    2.1  149.8   -7.2   21.6  -10.9   30.9]\n",
      "Offset -69.0\n",
      "Test accuracy 67.64705882352942% (230 of 340)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta, offset = init_params_with_ones(len(train_features[0]))\n",
    "theta, offset = train_perceptron_with_offset(theta, offset, train_features, train_target, 10)\n",
    "acc, correct, test_count = test_perceptron(theta, offset, test_features, test_target)\n",
    "print(f'Results after 10 epochs:\\n'\n",
    "      f'Theta {theta}\\nOffset {offset}\\n'\n",
    "      f'Test accuracy {acc*100}% ({correct} of {test_count})\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) With ones as initial parameters over 25 epochs with offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 25 epochs:\n",
      "Theta [ 233.  -392.3  887.2  271.1 -115.   -48.1  -21.8 -328.8   32.   357.6\n",
      "  247.   -42.   268.5  -15.4  268.3  109.    62.7  -34.5   18.3]\n",
      "Offset -158.0\n",
      "Test accuracy 67.64705882352942% (230 of 340)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta, offset = init_params_with_ones(len(train_features[0]))\n",
    "theta, offset = train_perceptron_with_offset(theta, offset, train_features, train_target, 25)\n",
    "acc, correct, test_count = test_perceptron(theta, offset, test_features, test_target)\n",
    "print(f'Results after 25 epochs:\\n'\n",
    "      f'Theta {theta}\\nOffset {offset}\\n'\n",
    "      f'Test accuracy {acc*100}% ({correct} of {test_count})\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What are your observations based on the subparts d), f) and g) given above [2 points: BONUS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TODO ## \n",
    "\n",
    "ANS: We can observe that there is not improvement in performance with the increase in epoch. This is a linearly unseparable case due to which perceptron keeps osciliating. We reach optimal solution after 1 epoch and keep oscillating after."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Stochastic Gradient with Hinge Loss \n",
    "This exercise requires the student to understand the basics of linear classification using stochastic gradient with hinge loss. We will be comparing our functions results with sklearn implementation of hinge loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Hinge-loss stochastic gradient descent classification from scratch, and compare their answers with scikit learn's implementation of Hinge Loss for sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should return the hinge loss (empirical risk) for your current theta vector: \"theta\" is your current theta vector, \"xs\" is the feature vectors from the training dataset.\n",
    "#\"ys\" is the output vector (the vector of \"labels\") This question worth [6 points]\n",
    "def hg_loss(theta, offset, xs, ys):\n",
    "    \n",
    "    ## TODO ##\n",
    "    ls = 1-((np.dot(xs,theta)+offset)*ys) \n",
    "    return sum([i if i>0 else 0 for i in ls ])/len(xs) \n",
    "    ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Through this function, you need to write from scratch of a stochastic gradient (using hinge-loss function) training algorithms with offset.\n",
    "#for the input: \"theta\" is the initial theta vector, \"xs\" is our feature vectors from the training dataset.\n",
    "#\"ys\" is the output vector (the vector of \"labels\"), \"epochs\" is the number of times your algorithm run through the whole training dataset.\n",
    "#This question worth [16 points]\n",
    "\n",
    "theta, offset = init_params_with_zeroes(len(train_features[0]))\n",
    "def train_SGD_with_hinge_loss(theta, offset, xs, ys, epochs):\n",
    "    ### TODO ##\n",
    "    k = 0\n",
    "    best_param = theta.copy() \n",
    "    best_offset = offset \n",
    "    best_loss = hg_loss(theta, offset, xs, ys) \n",
    "    order = [i for i in range(0,len(xs))]\n",
    "    random.Random(1).shuffle(order) \n",
    "    while epochs>0:\n",
    "        lr = 1/(k+1) \n",
    "        for n in order:\n",
    "            i,j = xs[n], ys[n]\n",
    "            if j*(np.dot(i, theta) + offset)<=1: \n",
    "                theta += i*j*lr \n",
    "                offset += j*lr \n",
    "                k+=1\n",
    "                lr = 1/(k+1)\n",
    "                loss = hg_loss(theta, offset, xs, ys)\n",
    "                if loss < best_loss: \n",
    "                    best_loss = loss\n",
    "                    best_param = theta.copy()\n",
    "                    best_offset = offset\n",
    "        epochs-=1\n",
    "            \n",
    "    print(best_param, best_offset)\n",
    "    return best_param, best_offset\n",
    "    ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14907788 -2.02624254  1.54461817  1.54274004  1.62954787 -0.12351234\n",
      "  0.67615154 -0.09220192  0.03879626  0.78925535  0.1372067  -0.05736686\n",
      "  1.25676939  1.18958245  1.45919306  1.68305942  0.68417092  1.24387874\n",
      "  0.99518122] 0.792644601032122\n",
      "Results after 10 epochs:\n",
      "Theta [ 0.14907788 -2.02624254  1.54461817  1.54274004  1.62954787 -0.12351234\n",
      "  0.67615154 -0.09220192  0.03879626  0.78925535  0.1372067  -0.05736686\n",
      "  1.25676939  1.18958245  1.45919306  1.68305942  0.68417092  1.24387874\n",
      "  0.99518122]\n",
      "Test accuracy 65.58823529411765% (223 of 340)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta, offset = init_params_with_ones(len(train_features[0]))\n",
    "theta, offset\n",
    "theta, offset = train_SGD_with_hinge_loss(theta, offset, train_features, train_target, 10)\n",
    "theta, offset\n",
    "acc, correct, test_count = test_perceptron(theta, offset, test_features, test_target)\n",
    "print(f'Results after 10 epochs:\\n'\n",
    "      f'Theta {theta}\\n'\n",
    "      f'Test accuracy {acc*100}% ({correct} of {test_count})\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.833422873861815"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Implementing Hinge Loss Using Scikit Learn Package and print the hinge loss [3 points]\n",
    "from sklearn.metrics import hinge_loss\n",
    "h_loss = hinge_loss(test_target, np.dot(test_features, theta) + offset) \n",
    "h_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8334228738618155"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg_loss(theta, offset, test_features, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if your hinge loss is working correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0.00001 > abs(hg_loss(theta, offset, test_features, test_target) - h_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
